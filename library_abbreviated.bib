@inproceedings{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proc. Conf. N. Am. Chapter Assoc. Comput. Linguist.: Hum. Lang. Technol.},
  year={2019},
}

@inproceedings{dai2019transformer,
  title={Transformer-xl: Attentive language models beyond a fixed-length context},
  author={Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime and Le, Quoc V and Salakhutdinov, Ruslan},
  booktitle = {Proc. Annu. Meet. Assoc. Comput. Linguist.},
  year      = {2019},
}

@inproceedings{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  booktitle={Proc. Adv. neural inf. proces. syst.},
  year={2020},
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Proc. Adv. neural inf. proces. syst.},
  pages={5998--6008},
  year={2017}
}

@inproceedings{yang2019xlnet,
  title={Xlnet: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Ruslan and Le, Quoc V},
  booktitle={Proc. Adv. neural inf. proces. syst.},
  year={2019},
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}


@inproceedings{
dosovitskiy2021an,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={Proc. Int. Conf. Learn. Representations},
year={2021},
url={https://openreview.net/forum?id=YicbFdNTTy}
}

@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  pages={213--229},
  year={2020},
  organization={Springer}
}

@article{beal2020toward,
  title={Toward transformer-based object detection},
  author={Beal, Josh and Kim, Eric and Tzeng, Eric and Park, Dong Huk and Zhai, Andrew and Kislyuk, Dmitry},
  journal={arXiv preprint arXiv:2012.09958},
  year={2020}
}

@article{strudel2021segmenter,
  title={Segmenter: Transformer for Semantic Segmentation},
  author={Strudel, Robin and Garcia, Ricardo and Laptev, Ivan and Schmid, Cordelia},
  journal={arXiv preprint arXiv:2105.05633},
  year={2021}
}

@inproceedings{zheng2021rethinking,
  title={Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers},
  author={Zheng, Sixiao and Lu, Jiachen and Zhao, Hengshuang and Zhu, Xiatian and Luo, Zekun and Wang, Yabiao and Fu, Yanwei and Feng, Jianfeng and Xiang, Tao and Torr, Philip HS and others},
  booktitle={Proc. IEEE Int. Conf. Computer Vis. Pattern Recognit.},
  pages={6881--6890},
  year={2021}
}

@article{caron2021emerging,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  journal={arXiv preprint arXiv:2104.14294},
  year={2021}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={Proc. Int. Conf. Mach. Learn.},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{ramesh2021zero,
  title={Zero-Shot Text-to-Image Generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  journal={arXiv preprint arXiv:2102.12092},
  year={2021}
}

@inproceedings{bhojanapalli2021understanding,
  title={Understanding robustness of transformers for image classification},
  author={Bhojanapalli, Srinadh and Chakrabarti, Ayan and Glasner, Daniel and Li, Daliang and Unterthiner, Thomas and Veit, Andreas},
  booktitle={Proc. IEEE Int. Conf. Comput. Vis.},
  pages={10231--10241},
  year={2021}
}

@article{shao2021adversarial,
  title={On the Adversarial Robustness of Vision Transformers},
  author={Shao, Rulin and Shi, Zhouxing and Yi, Jinfeng and Chen, Pin-Yu and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:2103.15670},
  year={2021}
}

@article{aldahdooh2021reveal,
  title={Reveal of Vision Transformers Robustness against Adversarial Attacks},
  author={Aldahdooh, Ahmed and Hamidouche, Wassim and Deforges, Olivier},
  journal={arXiv preprint arXiv:2106.03734},
  year={2021}
}

@article{mao2021rethinking,
  title={Rethinking the Design Principles of Robust Vision Transformer},
  author={Mao, Xiaofeng and Qi, Gege and Chen, Yuefeng and Li, Xiaodan and Ye, Shaokai and He, Yuan and Xue, Hui},
  journal={arXiv preprint arXiv:2105.07926},
  year={2021}
}

@inproceedings{fu2022patchfool,
title={Patch-Fool: Are Vision Transformers Always Robust Against Adversarial Perturbations?},
author={Yonggan Fu and Shunyao Zhang and Shang Wu and Cheng Wan and Yingyan Lin},
booktitle={Proc. Int. Conf. Learn. Representations},
year={2022},
url={https://openreview.net/forum?id=28ib9tf6zhr}
}

@article{bai2021transformers,
  title={Are Transformers more robust than CNNs?},
  author={Bai, Yutong and Mei, Jieru and Yuille, Alan L and Xie, Cihang},
  journal={Proc. Adv. neural inf. proces. syst.},
  volume={34},
  year={2021}
}

@article{shrikumar2016not,
  title={Not just a black box: Learning important features through propagating activation differences},
  author={Shrikumar, Avanti and Greenside, Peyton and Shcherbina, Anna and Kundaje, Anshul},
  journal={arXiv preprint arXiv:1605.01713},
  year={2016}
}

@article{smilkov2017smoothgrad,
  title={Smoothgrad: removing noise by adding noise},
  author={Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
  journal={arXiv preprint arXiv:1706.03825},
  year={2017}
}

@inproceedings{srinivas2019full,
  title={Full-gradient representation for neural network visualization},
  author={Srinivas, Suraj and Fleuret, Fran{\c{c}}ois},
  booktitle={Proc. Adv. neural inf. proces. syst.},
  pages={4126--4135},
  year={2019}
}

@inproceedings{li2018tell,
  title={Tell me where to look: Guided attention inference network},
  author={Li, Kunpeng and Wu, Ziyan and Peng, Kuan-Chuan and Ernst, Jan and Fu, Yun},
  booktitle={Proc. IEEE Int. Conf. Comput. Vis. Pattern Recognit.},
  pages={9215--9223},
  year={2018}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proc. IEEE Int. Conf. Comput. Vis.},
  pages={618--626},
  year={2017}
}

@article{bach2015pixel,
  title={On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation},
  author={Bach, Sebastian and Binder, Alexander and Montavon, Gr{\'e}goire and Klauschen, Frederick and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  journal={PloS one},
  volume={10},
  number={7},
  pages={e0130140},
  year={2015},
  publisher={Public Library of Science}
}

@inproceedings{shrikumar2017learning,
  title={Learning important features through propagating activation differences},
  author={Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={3145--3153},
  year={2017},
  organization={JMLR. org}
}

@article{jiang2021layercam,
  title={Layercam: Exploring hierarchical class activation maps for localization},
  author={Jiang, Peng-Tao and Zhang, Chang-Bin and Hou, Qibin and Cheng, Ming-Ming and Wei, Yunchao},
  journal={IEEE Trans. Image Process.},
  volume={30},
  pages={5875--5888},
  year={2021},
  publisher={IEEE}
}

@inproceedings{muhammad2020eigen,
  title={Eigen-cam: Class activation map using principal components},
  author={Muhammad, Mohammed Bany and Yeasin, Mohammed},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--7},
  year={2020},
  organization={IEEE}
}

@inproceedings{wang2020score,
  title={Score-CAM: Score-weighted visual explanations for convolutional neural networks},
  author={Wang, Haofan and Wang, Zifan and Du, Mengnan and Yang, Fan and Zhang, Zijian and Ding, Sirui and Mardziel, Piotr and Hu, Xia},
  booktitle={Proc. IEEE Int. Conf. Computer Vis. Pattern Recognit. Workshops},
  pages={24--25},
  year={2020}
}

@inproceedings{ramaswamy2020ablation,
  title={Ablation-cam: Visual explanations for deep convolutional network via gradient-free localization},
  author={Ramaswamy, Harish Guruprasad and others},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={983--991},
  year={2020}
}

@article{fu2020axiom,
  title={Axiom-based grad-cam: Towards accurate visualization and explanation of cnns},
  author={Fu, Ruigang and Hu, Qingyong and Dong, Xiaohu and Guo, Yulan and Gao, Yinghui and Li, Biao},
  journal={arXiv preprint arXiv:2008.02312},
  year={2020}
}

@inproceedings{chattopadhay2018grad,
  title={Grad-cam++: Generalized gradient-based visual explanations for deep convolutional networks},
  author={Chattopadhay, Aditya and Sarkar, Anirban and Howlader, Prantik and Balasubramanian, Vineeth N},
  booktitle={2018 IEEE winter conference on applications of computer vision (WACV)},
  pages={839--847},
  year={2018},
  organization={IEEE}
}

@misc{jacobgilpytorchcam,
  title={PyTorch library for CAM methods},
  author={Jacob Gildenblat and contributors},
  year={2021},
  publisher={GitHub},
  howpublished={\url{https://github.com/jacobgil/pytorch-grad-cam}},
}

@inproceedings{chefer2021transformer,
  title={Transformer interpretability beyond attention visualization},
  author={Chefer, Hila and Gur, Shir and Wolf, Lior},
  booktitle={Proc. IEEE Int. Conf. Computer Vis. Pattern Recognit.},
  pages={782--791},
  year={2021}
}

@inproceedings{chefer2021generic,
  title={Generic attention-model explainability for interpreting bi-modal and encoder-decoder transformers},
  author={Chefer, Hila and Gur, Shir and Wolf, Lior},
  booktitle={Proc. IEEE Int. Conf. Comput. Vis.},
  pages={397--406},
  year={2021}
}


@article{rauber2017foolboxnative,
  doi = {10.21105/joss.02607},
  url = {https://doi.org/10.21105/joss.02607},
  year = {2020},
  publisher = {The Open Journal},
  volume = {5},
  number = {53},
  pages = {2607},
  author = {Jonas Rauber and Roland Zimmermann and Matthias Bethge and Wieland Brendel},
  title = {Foolbox Native: Fast adversarial attacks to benchmark the robustness of machine learning models in PyTorch, TensorFlow, and JAX},
  journal = {J. Open Source Softw.}
}

@inproceedings{rauber2017foolbox,
  title={Foolbox: A Python toolbox to benchmark the robustness of machine learning models},
  author={Rauber, Jonas and Brendel, Wieland and Bethge, Matthias},
  booktitle={Reliable Machine Learning in the Wild Workshop, 34th International Conference on Machine Learning},
  year={2017},
  url={http://arxiv.org/abs/1707.04131},
}

@misc{rw2019timm,
  author = {Ross Wightman},
  title = {PyTorch Image Models},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  doi = {10.5281/zenodo.4414861},
  howpublished = {\url{https://github.com/rwightman/pytorch-image-models}}
}

@article{ilyas2019adversarial,
  title={Adversarial examples are not bugs, they are features},
  author={Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander},
  journal={Proc. Adv. neural inf. proces. syst.},
  volume={32},
  year={2019}
}

@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@inproceedings{madry2018towards,
  title={Towards Deep Learning Models Resistant to Adversarial Attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  booktitle={Proc. Int. Conf. Learn. Representations},
  year={2018}
}

@inproceedings{moosavi2016deepfool,
  title={Deepfool: a simple and accurate method to fool deep neural networks},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal},
  booktitle={Proc. IEEE Int. Conf. Comput. Vis. Pattern Recognit.},
  pages={2574--2582},
  year={2016}
}

@inproceedings{rony2019decoupling,
  title={Decoupling direction and norm for efficient gradient-based l2 adversarial attacks and defenses},
  author={Rony, J{\'e}r{\^o}me and Hafemann, Luiz G and Oliveira, Luiz S and Ayed, Ismail Ben and Sabourin, Robert and Granger, Eric},
  booktitle={Proc. IEEE Int. Conf. Computer Vis. Pattern Recognit.},
  pages={4322--4330},
  year={2019}
}

@article{DBLP:journals/tdsc/LiangLSLSW21,
  author    = {Bin Liang and
               Hongcheng Li and
               Miaoqiang Su and
               Xirong Li and
               Wenchang Shi and
               Xiaofeng Wang},
  title     = {Detecting Adversarial Image Examples in Deep Neural Networks with
               Adaptive Noise Reduction},
  journal   = {{IEEE} Trans. Dependable Secur. Comput.},
  volume    = {18},
  number    = {1},
  pages     = {72--85},
  year      = {2021},
  url       = {https://doi.org/10.1109/TDSC.2018.2874243},
  doi       = {10.1109/TDSC.2018.2874243},
  timestamp = {Sat, 09 Oct 2021 13:18:02 +0200},
  biburl    = {https://dblp.org/rec/journals/tdsc/LiangLSLSW21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proc. IEEE Int. Conf. Comput. Vis.},
  pages={10012--10022},
  year={2021}
}

@inproceedings{meng2017magnet,
  title={Magnet: a two-pronged defense against adversarial examples},
  author={Meng, Dongyu and Chen, Hao},
  booktitle={Proceedings of the 2017 ACM SIGSAC conference on computer and communications security},
  pages={135--147},
  year={2017}
}

@inproceedings{li2021patch,
  title={Patch Vestiges in the Adversarial Examples Against Vision Transformer Can Be Leveraged for Adversarial Detection},
  author={Li, Juzheng},
  booktitle={The AAAI-22 Workshop on Adversarial Machine Learning and Beyond},
  year={2021}
}

@software{Howard_Imagenette_2019,
    title={Imagenette: A smaller subset of 10 easily classified classes from Imagenet},
    author={Jeremy Howard},
    year={2019},
    month={March},
    publisher = {GitHub},
    url = {https://github.com/fastai/imagenette}
}

@article{ignatiev2019relating,
  title={On relating explanations and adversarial examples},
  author={Ignatiev, Alexey and Narodytska, Nina and Marques-Silva, Joao},
  journal={Proc. Adv. neural inf. proces. syst.},
  volume={32},
  year={2019}
}

@inproceedings{ignatiev2019abduction,
  title={Abduction-based explanations for machine learning models},
  author={Ignatiev, Alexey and Narodytska, Nina and Marques-Silva, Joao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={1511--1519},
  year={2019}
}

@inproceedings{liu2018adversarial,
  title={Adversarial detection with model interpretation},
  author={Liu, Ninghao and Yang, Hongxia and Hu, Xia},
  booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={1803--1811},
  year={2018}
}

@inproceedings{ross2018improving,
  title={Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients},
  author={Ross, Andrew and Doshi-Velez, Finale},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{sundararajan2017axiomatic,
  title={Axiomatic attribution for deep networks},
  author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  booktitle={Proc. Int. Conf. Mach. Learn.},
  pages={3319--3328},
  year={2017},
  organization={PMLR}
}

@inproceedings{xu2019structured,
  title={Structured Adversarial Attack: Towards General Implementation and Better Interpretability},
  author={Xu, Kaidi and Liu, Sijia and Zhao, Pu and Chen, Pin-Yu and Zhang, Huan and Fan, Quanfu and Erdogmus, Deniz and Wang, Yanzhi and Lin, Xue},
  booktitle={ICLR (Poster)},
  year={2019}
}

@inproceedings{chalasani2020concise,
  title={Concise explanations of neural networks using adversarial training},
  author={Chalasani, Prasad and Chen, Jiefeng and Chowdhury, Amrita Roy and Wu, Xi and Jha, Somesh},
  booktitle={Proc. Int. Conf. Mach. Learn.},
  pages={1383--1391},
  year={2020},
  organization={PMLR}
}

@inproceedings{pawelczyk2022exploring,
  title={Exploring counterfactual explanations through the lens of adversarial examples: A theoretical and empirical analysis},
  author={Pawelczyk, Martin and Agarwal, Chirag and Joshi, Shalmali and Upadhyay, Sohini and Lakkaraju, Himabindu},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4574--4594},
  year={2022},
  organization={PMLR}
}

@inproceedings{Christian2014Intriguing,
  author    = {Christian Szegedy and
               Wojciech Zaremba and
               Ilya Sutskever and
               Joan Bruna and
               Dumitru Erhan and
               Ian J. Goodfellow and
               Rob Fergus},
  title     = {Intriguing properties of neural networks},
  booktitle = {{ICLR} (Poster)},
  year      = {2014}
}

@inproceedings{yang2020ml,
  title={Ml-loo: Detecting adversarial examples with feature attribution},
  author={Yang, Puyudi and Chen, Jianbo and Hsieh, Cho-Jui and Wang, Jane-Ling and Jordan, Michael},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={6639--6647},
  year={2020}
}

@inproceedings{cintas2021detecting,
  title={Detecting adversarial attacks via subset scanning of autoencoder activations and reconstruction error},
  author={Cintas, Celia and Speakman, Skyler and Akinwande, Victor and Ogallo, William and Weldemariam, Komminist and Sridharan, Srihari and McFowland, Edward},
  booktitle={Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence},
  pages={876--882},
  year={2021}
}

@article{xiao2017fashion,
  title={Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms},
  author={Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  journal={arXiv preprint arXiv:1708.07747},
  year={2017}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}